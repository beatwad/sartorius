{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-08T06:39:05.823859Z",
     "iopub.status.busy": "2021-12-08T06:39:05.823458Z",
     "iopub.status.idle": "2021-12-08T06:39:06.618058Z",
     "shell.execute_reply": "2021-12-08T06:39:06.617189Z",
     "shell.execute_reply.started": "2021-12-08T06:39:05.823814Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Logger detectron2 (DEBUG)>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%config Completer.use_jedi = False # use autocompletion\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import detectron2\n",
    "from pathlib import Path\n",
    "import random, cv2, os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pycocotools.mask as mask_util\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor, DefaultTrainer\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer, ColorMode\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.utils.logger import setup_logger\n",
    "from detectron2.evaluation.evaluator import DatasetEvaluator\n",
    "from detectron2.engine import BestCheckpointer\n",
    "from detectron2.checkpoint import DetectionCheckpointer\n",
    "# import PyCOCO tools\n",
    "from pycocotools.coco import COCO\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "\n",
    "setup_logger()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this to unregister datasets\n",
    "# DatasetCatalog.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-08T06:39:07.448554Z",
     "iopub.status.busy": "2021-12-08T06:39:07.448290Z",
     "iopub.status.idle": "2021-12-08T06:39:20.510965Z",
     "shell.execute_reply": "2021-12-08T06:39:20.510200Z",
     "shell.execute_reply.started": "2021-12-08T06:39:07.448522Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/10 11:47:47 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from sartorius-coco-dataset-5-fold-split/annotations_val_fold_3.json\n"
     ]
    }
   ],
   "source": [
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"Misc/cascade_mask_rcnn_X_152_32x8d_FPN_IN5k_gn_dconv.yaml\"))\n",
    "# cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x.yaml\"))\n",
    "cfg.INPUT.MASK_FORMAT='bitmask'\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 3 \n",
    "cfg.MODEL.WEIGHTS = 'output/model_best_fold_3.pth'  \n",
    "cfg.TEST.DETECTIONS_PER_IMAGE = 1000\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5\n",
    "predictor = DefaultPredictor(cfg)\n",
    "\n",
    "dataDir=Path('sartorius-cell-instance-segmentation')\n",
    "\n",
    "register_coco_instances('sartorius_val',{},'sartorius-coco-dataset-5-fold-split/annotations_val_fold_3.json', dataDir)\n",
    "val_ds = DatasetCatalog.get('sartorius_val')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-08T06:40:31.241933Z",
     "iopub.status.busy": "2021-12-08T06:40:31.241567Z",
     "iopub.status.idle": "2021-12-08T06:41:39.249170Z",
     "shell.execute_reply": "2021-12-08T06:41:39.248485Z",
     "shell.execute_reply.started": "2021-12-08T06:40:31.241897Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91d95d62b6404f8687636f5a5a9d0ed9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bc83bdce10e4ec49ebf6f274b183b1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class number is 2, pixel thresh is 0, score is 0.29948435705304083\n",
      "Class number is 2, pixel thresh is 10, score is 0.29948435705304083\n",
      "Class number is 2, pixel thresh is 20, score is 0.29948435705304083\n",
      "Class number is 2, pixel thresh is 30, score is 0.29948435705304083\n",
      "Class number is 2, pixel thresh is 40, score is 0.29999975132111534\n",
      "Class number is 2, pixel thresh is 50, score is 0.3002182680550654\n",
      "Class number is 2, pixel thresh is 60, score is 0.30015466549201675\n",
      "Class number is 2, pixel thresh is 70, score is 0.3001756752994107\n",
      "Class number is 2, pixel thresh is 80, score is 0.30016561264238273\n",
      "Class number is 2, pixel thresh is 90, score is 0.3000052437785372\n",
      "Class number is 2, pixel thresh is 100, score is 0.2995302225839123\n",
      "Class number is 2, pixel thresh is 110, score is 0.2972712317200991\n",
      "Class number is 2, pixel thresh is 120, score is 0.2930174995705327\n",
      "Class number is 2, pixel thresh is 130, score is 0.2860291362131131\n",
      "Class number is 2, pixel thresh is 140, score is 0.2757546105985645\n",
      "Class number is 2, pixel thresh is 150, score is 0.26319628421731184\n",
      "Class number is 2, pixel thresh is 160, score is 0.24933211477969447\n",
      "Class number is 2, pixel thresh is 170, score is 0.2378111580686553\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fe0feaae45948f5a7a5a8a12034df7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class number is 3, pixel thresh is 0, score is 0.3001506761530878\n",
      "Class number is 3, pixel thresh is 10, score is 0.3001506761530878\n",
      "Class number is 3, pixel thresh is 20, score is 0.3001564190628505\n",
      "Class number is 3, pixel thresh is 30, score is 0.3001564190628505\n",
      "Class number is 3, pixel thresh is 40, score is 0.30016647692872095\n",
      "Class number is 3, pixel thresh is 50, score is 0.30020087463571554\n",
      "Class number is 3, pixel thresh is 60, score is 0.3002182680550654\n",
      "Class number is 3, pixel thresh is 70, score is 0.3001930207064018\n",
      "Class number is 3, pixel thresh is 80, score is 0.30018873818823855\n",
      "Class number is 3, pixel thresh is 90, score is 0.3001676157899068\n",
      "Class number is 3, pixel thresh is 100, score is 0.3000964462484423\n",
      "Class number is 3, pixel thresh is 110, score is 0.29965593320632805\n",
      "Class number is 3, pixel thresh is 120, score is 0.29915449726634047\n",
      "Class number is 3, pixel thresh is 130, score is 0.29821831192831927\n",
      "Class number is 3, pixel thresh is 140, score is 0.29703364119900083\n",
      "Class number is 3, pixel thresh is 150, score is 0.295405186060415\n",
      "Class number is 3, pixel thresh is 160, score is 0.29340435355499\n",
      "Class number is 3, pixel thresh is 170, score is 0.29142888746862095\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([(0, 0), (0, 0), (0.4, 0.2978835996437557)],\n",
       " [(0, 0), (50, 0.3002182680550654), (60, 0.3002182680550654)])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def precision_at(threshold, iou):\n",
    "    matches = iou > threshold\n",
    "    true_positives = np.sum(matches, axis=1) == 1  # Correct objects\n",
    "    false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n",
    "    false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n",
    "    return np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n",
    "\n",
    "def score(pred, targ, thresholds, pixels):\n",
    "    pred_class = torch.mode(pred['instances'].pred_classes)[0]\n",
    "    # save only masks that fit in threshold\n",
    "    take = pred['instances'].scores >= thresholds[pred_class]\n",
    "    pred_masks = pred['instances'].pred_masks[take]\n",
    "    pred_masks = pred_masks.cpu().numpy()\n",
    "    # save only masks with size more than MIN_PIXELS\n",
    "    res_masks = []\n",
    "    for mask in pred_masks:\n",
    "        if mask.sum() >= pixels[pred_class]: # skip predictions with small area\n",
    "            res_masks.append(mask)\n",
    "    # score the result masks\n",
    "    enc_preds = [mask_util.encode(np.asarray(p, order='F')) for p in res_masks]\n",
    "    enc_targs = list(map(lambda x:x['segmentation'], targ['annotations']))\n",
    "    ious = mask_util.iou(enc_preds, enc_targs, [0]*len(enc_targs))\n",
    "    prec = []\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        tp, fp, fn = precision_at(t, ious)\n",
    "        p = tp / (tp + fp + fn)\n",
    "        prec.append(p)\n",
    "    return np.mean(prec)\n",
    "\n",
    "def score_all(thresholds, pixels):\n",
    "    scores = []\n",
    "    for item in val_ds:\n",
    "        im =  cv2.imread(item['file_name'])\n",
    "        pred = predictor(im)       \n",
    "        sc = score(pred, item, thresholds, pixels)\n",
    "        scores.append(sc)\n",
    "    return np.mean(scores)\n",
    "\n",
    "thresholds = [0.5, 0.6, 0.5]\n",
    "pixels = [50, 60, 60]\n",
    "\n",
    "# best_threshs = [(0, 0), (0, 0), (0, 0)]\n",
    "\n",
    "# for i in tqdm(range(2, 3)):\n",
    "#     best_score = 0\n",
    "#     for j in tqdm(np.arange(0.4, 0.75, 0.025)):\n",
    "#         thresholds[i] = j\n",
    "#         curr_score = score_all(thresholds, pixels)\n",
    "#         if curr_score > best_score:\n",
    "#             best_score = curr_score\n",
    "#             best_threshs[i] = (j, best_score)\n",
    "#         print(f'Class number is {i+1}, threshold is {round(j, 2)}, score is {curr_score}')\n",
    "#     thresholds[i] = best_threshs[i][0]\n",
    "    \n",
    "best_pixels = [(0, 0), (0, 0), (0, 0)]\n",
    "# thresholds = [i[0] for i in best_threshs]\n",
    "\n",
    "for i in tqdm(range(1, 3)):\n",
    "    best_score = 0\n",
    "    for j in tqdm(np.arange(0, 180, 10)):\n",
    "        pixels[i] = j\n",
    "        curr_score = score_all(thresholds, pixels)\n",
    "        if curr_score > best_score:\n",
    "            best_score = curr_score\n",
    "            best_pixels[i] = (j, best_score)\n",
    "        print(f'Class number is {i+1}, pixel thresh is {round(j, 2)}, score is {curr_score}')\n",
    "    pixels[i] = best_pixels[i][0]\n",
    "    \n",
    "best_threshs, best_pixels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results of grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "score_all([0.5, 0.65, 0.5], [70, 75, 70])  # val acc 2896, LB 3070, fold 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_all([0.5, 0.575, 0.5], [60, 60, 130])  # val acc 2870, LB 3150 fold 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_all([0.5, 0.6, 0.5], [50, 60, 50])  # val acc 3002, LB 3090 fold 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_all([0.5, 0.6, 0.5], [50, 50, 60])  # val acc 3002, LB 3090 fold 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets look at some of the validation files to check if things look reasonable\n",
    "\n",
    "We show predictions on the left and ground truth on the right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-08T06:44:45.144001Z",
     "iopub.status.busy": "2021-12-08T06:44:45.143362Z",
     "iopub.status.idle": "2021-12-08T06:44:56.225251Z",
     "shell.execute_reply": "2021-12-08T06:44:56.221761Z",
     "shell.execute_reply.started": "2021-12-08T06:44:45.143960Z"
    }
   },
   "outputs": [],
   "source": [
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5   # set a custom testing threshold\n",
    "predictor = DefaultPredictor(cfg)\n",
    "dataset_dicts = DatasetCatalog.get('sartorius_val')\n",
    "outs = []\n",
    "for d in random.sample(dataset_dicts, 3):    \n",
    "    im = cv2.imread(d[\"file_name\"])\n",
    "    outputs = predictor(im)  # format is documented at https://detectron2.readthedocs.io/tutorials/models.html#model-output-format\n",
    "    v = Visualizer(im[:, :, ::-1],\n",
    "                   metadata = MetadataCatalog.get('sartorius_train'), \n",
    "                    \n",
    "                   instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels. This option is only available for segmentation models\n",
    "    )\n",
    "    out_pred = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "    visualizer = Visualizer(im[:, :, ::-1], metadata=MetadataCatalog.get('sartorius_train'))\n",
    "    out_target = visualizer.draw_dataset_dict(d)\n",
    "    outs.append(out_pred)\n",
    "    outs.append(out_target)\n",
    "_,axs = plt.subplots(len(outs)//2,2,figsize=(40,45))\n",
    "for ax, out in zip(axs.reshape(-1), outs):\n",
    "    ax.imshow(out.get_image()[:, :, ::-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
