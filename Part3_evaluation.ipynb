{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c084408b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Logger detectron2 (DEBUG)>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%config Completer.use_jedi = False # use autocompletion\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import detectron2\n",
    "from pathlib import Path\n",
    "import random, cv2, os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pycocotools.mask as mask_util\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor, DefaultTrainer\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer, ColorMode\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.utils.logger import setup_logger\n",
    "from detectron2.evaluation.evaluator import DatasetEvaluator\n",
    "from detectron2.engine import BestCheckpointer\n",
    "from detectron2.checkpoint import DetectionCheckpointer\n",
    "# import PyCOCO tools\n",
    "from pycocotools.coco import COCO\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "\n",
    "setup_logger()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e9e9af",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a25ce0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[11/23 16:28:52 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from sartorius-cell-instance-segmentation-coco/annotations_val.json\n"
     ]
    }
   ],
   "source": [
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x.yaml\"))\n",
    "cfg.INPUT.MASK_FORMAT='bitmask'\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 3 \n",
    "cfg.MODEL.WEIGHTS = './output/model_best.pth'  \n",
    "cfg.TEST.DETECTIONS_PER_IMAGE = 1000\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5\n",
    "predictor = DefaultPredictor(cfg)\n",
    "\n",
    "dataDir=Path('sartorius-cell-instance-segmentation')\n",
    "\n",
    "register_coco_instances('sartorius_val',{},'sartorius-cell-instance-segmentation-coco/annotations_val.json', dataDir)\n",
    "val_ds = DatasetCatalog.get('sartorius_val')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271cfd97",
   "metadata": {},
   "source": [
    "# Set hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d73c0073",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/anaconda3/envs/sartorius/lib/python3.9/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1634272204863/work/aten/src/ATen/native/TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.31491995903836956"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "THRESHOLDS = [.25, .35, .35]\n",
    "MIN_PIXELS = [20, 65, 40]\n",
    "\n",
    "def precision_at(threshold, iou):\n",
    "    matches = iou > threshold\n",
    "    true_positives = np.sum(matches, axis=1) == 1  # Correct objects\n",
    "    false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n",
    "    false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n",
    "    return np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n",
    "\n",
    "def score(pred, targ):\n",
    "    pred_class = torch.mode(pred['instances'].pred_classes)[0]\n",
    "    # save only masks that fit in threshold\n",
    "    take = pred['instances'].scores >= THRESHOLDS[pred_class]\n",
    "    pred_masks = pred['instances'].pred_masks[take]\n",
    "    pred_masks = pred_masks.cpu().numpy()\n",
    "    # save only masks with size more than MIN_PIXELS\n",
    "    res_masks = []\n",
    "    for mask in pred_masks:\n",
    "        if mask.sum() >= MIN_PIXELS[pred_class]: # skip predictions with small area\n",
    "            res_masks.append(mask)\n",
    "    # score the result masks\n",
    "    enc_preds = [mask_util.encode(np.asarray(p, order='F')) for p in res_masks]\n",
    "    enc_targs = list(map(lambda x:x['segmentation'], targ['annotations']))\n",
    "    ious = mask_util.iou(enc_preds, enc_targs, [0]*len(enc_targs))\n",
    "    prec = []\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        tp, fp, fn = precision_at(t, ious)\n",
    "        p = tp / (tp + fp + fn)\n",
    "        prec.append(p)\n",
    "    return np.mean(prec)\n",
    "\n",
    "def score_all():\n",
    "    scores = []\n",
    "    for item in val_ds:\n",
    "        im =  cv2.imread(item['file_name'])\n",
    "        pred = predictor(im)       \n",
    "        \n",
    "        sc = score(pred, item)\n",
    "        scores.append(sc)\n",
    "        \n",
    "    return np.mean(scores)\n",
    "\n",
    "score_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a602c3c3",
   "metadata": {},
   "source": [
    "## Lets look at some of the validation files to check if things look reasonable\n",
    "\n",
    "We show predictions on the left and ground truth on the right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557d602e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.MODEL.WEIGHTS = os.path.join('./output', 'model_best.pth')  # path to the model we just trained\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5   # set a custom testing threshold\n",
    "predictor = DefaultPredictor(cfg)\n",
    "dataset_dicts = DatasetCatalog.get('sartorius_val')\n",
    "outs = []\n",
    "for d in random.sample(dataset_dicts, 3):    \n",
    "    im = cv2.imread(d[\"file_name\"])\n",
    "    outputs = predictor(im)  # format is documented at https://detectron2.readthedocs.io/tutorials/models.html#model-output-format\n",
    "    v = Visualizer(im[:, :, ::-1],\n",
    "                   metadata = MetadataCatalog.get('sartorius_train'), \n",
    "                    \n",
    "                   instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels. This option is only available for segmentation models\n",
    "    )\n",
    "    out_pred = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "    visualizer = Visualizer(im[:, :, ::-1], metadata=MetadataCatalog.get('sartorius_train'))\n",
    "    out_target = visualizer.draw_dataset_dict(d)\n",
    "    outs.append(out_pred)\n",
    "    outs.append(out_target)\n",
    "_,axs = plt.subplots(len(outs)//2,2,figsize=(40,45))\n",
    "for ax, out in zip(axs.reshape(-1), outs):\n",
    "    ax.imshow(out.get_image()[:, :, ::-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
