{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f35da72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Logger detectron2 (DEBUG)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%config Completer.use_jedi = False # use autocompletion\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import detectron2\n",
    "from pathlib import Path\n",
    "import random, cv2, os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pycocotools.mask as mask_util\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor, DefaultTrainer\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer, ColorMode\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.utils.logger import setup_logger\n",
    "from detectron2.evaluation.evaluator import DatasetEvaluator\n",
    "from detectron2.engine import BestCheckpointer\n",
    "from detectron2.checkpoint import DetectionCheckpointer\n",
    "# import PyCOCO tools\n",
    "from pycocotools.coco import COCO\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "# import ensemble tools\n",
    "from fastcore.all import *\n",
    "from ensemble_boxes import *\n",
    "\n",
    "setup_logger()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89f10b5",
   "metadata": {},
   "source": [
    "### Initiate a Predictor from our trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66a522a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all loaded:\n",
      "thresholds: [[0.18, 0.38, 0.58], [0.18, 0.38, 0.58]]\n",
      "models: ['R_50_FPN.pth', 'R_101_FPN.pth']\n"
     ]
    }
   ],
   "source": [
    "best_model=({'file': 'R_50_FPN.pth',\n",
    "              'config_name':'COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml', \n",
    "              'LB score': 0.297,\n",
    "              'pixels': [75, 150, 75],\n",
    "              'ths':[.18, .38, .58]},\n",
    "            {'file': 'R_101_FPN.pth',\n",
    "              'config_name':'COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x.yaml', \n",
    "              'LB score': 0.295,\n",
    "              'pixels': [75, 150, 75],\n",
    "              'ths':[.18, .38, .58]})\n",
    "\n",
    "mdl_path = \"output\"\n",
    "DATA_PATH = \"sartorius-cell-instance-segmentation\"\n",
    "MODELS = []\n",
    "BEST_MODELS =[]\n",
    "THSS = []\n",
    "PXLS = []\n",
    "ID_TEST = 0\n",
    "SUBM_PATH = f'{DATA_PATH}/test'\n",
    "SINGLE_MODE = False\n",
    "NMS = True\n",
    "MIN_PIXELS = [75, 150, 75]\n",
    "IOU_TH = .4\n",
    "for b_m in best_model:\n",
    "    model_name=b_m[\"file\"]\n",
    "    model_ths=b_m[\"ths\"]\n",
    "    model_pxl = b_m[\"pixels\"]\n",
    "    config_name=b_m[\"config_name\"]\n",
    "    BEST_MODELS.append(model_name)\n",
    "    THSS.append(model_ths)\n",
    "    PXLS.append(model_pxl)\n",
    "    cfg = get_cfg()\n",
    "    cfg.merge_from_file(model_zoo.get_config_file(config_name))\n",
    "    cfg.INPUT.MASK_FORMAT = 'bitmask'\n",
    "    cfg.MODEL.ROI_HEADS.NUM_CLASSES = 3 \n",
    "    cfg.MODEL.WEIGHTS = f'{mdl_path}/{model_name}'  \n",
    "    cfg.TEST.DETECTIONS_PER_IMAGE = 1000\n",
    "    MODELS.append(DefaultPredictor(cfg))\n",
    "print(f'all loaded:\\nthresholds: {THSS}\\nmodels: {BEST_MODELS}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c645dc7f",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba5bade7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From https://www.kaggle.com/stainsby/fast-tested-rle\n",
    "def rle_decode(mask_rle, shape=(520, 704)):\n",
    "    '''\n",
    "    mask_rle: run-length as string formated (start length)\n",
    "    shape: (height,width) of array to return \n",
    "    Returns numpy array, 1 - mask, 0 - background\n",
    "\n",
    "    '''\n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "    return img.reshape(shape)  # Needed to align to RLE direction\n",
    "\n",
    "def rle_encode(img):\n",
    "    '''\n",
    "    img: numpy array, 1 - mask, 0 - background\n",
    "    Returns run length as string formated\n",
    "    '''\n",
    "    pixels = img.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "def pred_masks(file_name, path, model, ths, min_pixels):\n",
    "    img = cv2.imread(f'{path}/{file_name}')\n",
    "    output = model(img)\n",
    "    pred_classes = output['instances'].pred_classes.cpu().numpy().tolist()\n",
    "    pred_class = max(set(pred_classes), key=pred_classes.count)\n",
    "    take = output['instances'].scores >= ths[pred_class]\n",
    "    pred_masks = output['instances'].pred_masks[take]\n",
    "    pred_masks = pred_masks.cpu().numpy()\n",
    "    res = []\n",
    "    used = np.zeros(img.shape[:2], dtype=int) \n",
    "    for i, mask in enumerate(pred_masks):\n",
    "        mask = mask * (1 - used)\n",
    "        if mask.sum() >= min_pixels[pred_class]:\n",
    "            used += mask\n",
    "            result.append(rle_encode(mask))\n",
    "    return res\n",
    "\n",
    "def ensemble_preds(file_name, path, models, ths):\n",
    "    img = cv2.imread(f'{path}/{file_name}')\n",
    "    classes = []\n",
    "    scores = []\n",
    "    bboxes = []\n",
    "    masks = []\n",
    "    for i, model in enumerate(models):\n",
    "        output = model(img)\n",
    "        pred_classes = output['instances'].pred_classes.cpu().numpy().tolist()\n",
    "        pred_class = max(set(pred_classes), key=pred_classes.count)\n",
    "        take = output['instances'].scores >= ths[i][pred_class]\n",
    "        classes.extend(output['instances'].pred_classes[take].cpu().numpy().tolist())\n",
    "        scores.extend(output['instances'].scores[take].cpu().numpy().tolist())\n",
    "        bboxes.extend(output['instances'].pred_boxes[take].tensor.cpu().numpy().tolist())\n",
    "        masks.extend(output['instances'].pred_masks[take].cpu().numpy())\n",
    "    assert len(classes) == len(masks) , 'ensemble lenght mismatch'\n",
    "    #scores, classes, bboxes, masks = zip(*sorted(zip(scores, classes, bboxes, masks),reverse=True))\n",
    "    return classes, scores, bboxes, masks\n",
    "\n",
    "def nms_predictions(classes, scores, bboxes, masks, iou_th=.5, shape=(520, 704)):\n",
    "    he, wd = shape[0], shape[1]\n",
    "    boxes_list = [[x[0] / wd, x[1] / he, x[2] / wd, x[3] / he]\n",
    "                  for x in bboxes]\n",
    "    scores_list = [x for x in scores]\n",
    "    labels_list = [x for x in classes]\n",
    "    nms_bboxes, nms_scores, nms_classes = nms(\n",
    "        boxes=[boxes_list], \n",
    "        scores=[scores_list], \n",
    "        labels=[labels_list], \n",
    "        weights=None,\n",
    "        iou_thr=iou_th\n",
    "    )\n",
    "    nms_masks = []\n",
    "    for s in nms_scores:\n",
    "        nms_masks.append(masks[scores.index(s)])\n",
    "    nms_scores, nms_classes, nms_masks = zip(*sorted(zip(nms_scores, nms_classes, nms_masks), reverse=True))\n",
    "    return nms_classes, nms_scores, nms_masks\n",
    "\n",
    "def ensemble_pred_masks(masks, classes, min_pixels, shape=(520, 704)):\n",
    "    result = []\n",
    "    pred_class = max(set(classes), key=classes.count)\n",
    "    used = np.zeros(shape, dtype=int) \n",
    "    for i, mask in enumerate(masks):\n",
    "        mask = mask * (1 - used)\n",
    "        if mask.sum() >= min_pixels[pred_class]:\n",
    "            used += mask\n",
    "            result.append(rle_encode(mask))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0da04f4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Path('sartorius-cell-instance-segmentation/test/7ae19de7bc2a.png'),\n",
       " Path('sartorius-cell-instance-segmentation/test/d8bfd1dafdc4.png'),\n",
       " Path('sartorius-cell-instance-segmentation/test/d48ec7815252.png')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataDir=Path('sartorius-cell-instance-segmentation')\n",
    "\n",
    "ids, masks=[],[]\n",
    "PATHGLOB = Path(DATA_PATH + '/test').glob('./*')\n",
    "test_names = [fil for fil in PATHGLOB]\n",
    "test_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8186ee07",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_masks_single = pred_masks(\n",
    "    test_names[ID_TEST], \n",
    "    path=SUBM_PATH, \n",
    "    model=MODELS[0],\n",
    "    ths=THSS[0],\n",
    "    min_pixels=MIN_PIXELS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41acb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes, scores, bboxes, masks = ensemble_preds(\n",
    "    file_name=test_names[ID_TEST] , \n",
    "    path=SUBM_PATH, \n",
    "    models=MODELS, \n",
    "    ths=THSS\n",
    ")\n",
    "if NMS:\n",
    "    classes, scores, masks = nms_predictions(\n",
    "        classes, \n",
    "        scores, \n",
    "        bboxes,\n",
    "        masks, iou_th=IOU_TH\n",
    "    )\n",
    "encoded_masks = ensemble_pred_masks(masks, classes, min_pixels=MIN_PIXELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6165578f",
   "metadata": {},
   "source": [
    "### Look at the outputs on a sample test file to sanity check\n",
    "I'm encoding here in the competition format and decoding back to bit mask just to make sure everything is fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c80115",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# encoded_masks = get_masks(test_names[0], predictor)\n",
    "\n",
    "# _, axs = plt.subplots(1,2, figsize=(60,25))\n",
    "# axs[1].imshow(cv2.imread(str(test_names[0])))\n",
    "# for enc in encoded_masks:\n",
    "#     dec = rle_decode(enc)\n",
    "#     axs[0].imshow(np.ma.masked_where(dec==0, dec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c69aa79",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# encoded_masks = get_masks(test_names[2], predictor)\n",
    "\n",
    "# _, axs = plt.subplots(1,2, figsize=(60,25))\n",
    "# axs[1].imshow(cv2.imread(str(test_names[2])))\n",
    "# for enc in encoded_masks:\n",
    "#     dec = rle_decode(enc)\n",
    "#     axs[0].imshow(np.ma.masked_where(dec==0, dec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fa104d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# encoded_masks = get_masks(test_names[1], predictor)\n",
    "\n",
    "# _, axs = plt.subplots(1,2, figsize=(60,25))\n",
    "# axs[1].imshow(cv2.imread(str(test_names[1])))\n",
    "# for enc in encoded_masks:\n",
    "#     dec = rle_decode(enc)\n",
    "#     axs[0].imshow(np.ma.masked_where(dec==0, dec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84efc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axs = plt.subplots(2, 2, figsize=(14, 8))\n",
    "axs[0][0].imshow(cv2.imread(f'{SUBM_PATH}/{test_names[ID_TEST]}'))\n",
    "axs[0][0].axis('off')\n",
    "axs[0][0].set_title(test_names[ID_TEST])\n",
    "for en_mask in encoded_masks_single:\n",
    "    dec_mask = rle_decode(en_mask)\n",
    "    axs[0][1].imshow(np.ma.masked_where(dec_mask == 0, dec_mask))\n",
    "    axs[0][1].axis('off')\n",
    "    axs[0][1].set_title('single model')\n",
    "axs[1][0].imshow(cv2.imread(f'{SUBM_PATH}/{test_names[ID_TEST]}'))\n",
    "axs[1][0].axis('off')\n",
    "axs[1][0].set_title(test_names[ID_TEST])\n",
    "for en_mask in encoded_masks:\n",
    "    dec_mask = rle_decode(en_mask)\n",
    "    axs[1][1].imshow(np.ma.masked_where(dec_mask == 0, dec_mask))\n",
    "    axs[1][1].axis('off')\n",
    "    axs[1][1].set_title('ensemble models')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a444e94c",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4404f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "subm_ids, subm_masks = [], []\n",
    "for test_name in tqdm(test_names):\n",
    "    if SINGLE_MODE:\n",
    "        encoded_masks = pred_masks(\n",
    "            test_name, \n",
    "            path=SUBM_PATH, \n",
    "            model=MODELS[0],\n",
    "            ths=THSS[0],\n",
    "            min_pixels=MIN_PIXELS\n",
    "        )\n",
    "    else:\n",
    "        classes, scores, bboxes, masks = ensemble_preds(\n",
    "            file_name=test_name, \n",
    "            path=SUBM_PATH, \n",
    "            models=MODELS, \n",
    "            ths=THSS\n",
    "        )\n",
    "        if NMS:\n",
    "            classes, scores, masks = nms_predictions(\n",
    "                classes, \n",
    "                scores, \n",
    "                bboxes, \n",
    "                masks, \n",
    "                iou_th=IOU_TH\n",
    "            )\n",
    "        encoded_masks = ensemble_pred_masks(\n",
    "            masks, \n",
    "            classes, \n",
    "            min_pixels=MIN_PIXELS\n",
    "        )\n",
    "    for enc_mask in encoded_masks:\n",
    "        subm_ids.append(test_name[:test_name.find('.')])\n",
    "        subm_masks.append(enc_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77741b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'id':ids, 'predicted':masks}).to_csv('submission.csv', index=False)\n",
    "pd.read_csv('submission.csv').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bbe0eb5",
   "metadata": {},
   "source": [
    "# Futher ideas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb68949",
   "metadata": {},
   "source": [
    "- ensemble\n",
    "- take data from LiveCELL directory and use it for further training of your model\n",
    "- broken masks - do you need to repair them?\n",
    "- train without validation?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
